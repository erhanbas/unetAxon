{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/base/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from utils.custom_generator import custom_image_generator\n",
    "from utils.image import ImageDataGenerator\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 82s 7us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# load the data and split to training and validation sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension (-1) must be in the range [0, 2), where 2 is the number of dimensions in the input. for 'metrics/acc/ArgMax' (op: 'ArgMax') with input shapes: [?,?], [].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    669\u001b[0m           \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors_as_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           status)\n\u001b[0m\u001b[1;32m    671\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension (-1) must be in the range [0, 2), where 2 is the number of dimensions in the input. for 'metrics/acc/ArgMax' (op: 'ArgMax') with input shapes: [?,?], [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b5186d999049>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m model.compile(loss=keras.losses.categorical_crossentropy,\n\u001b[1;32m     17\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m               metrics=['accuracy'])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m                            \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                            \u001b[0mtarget_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                            **kwargs)\n\u001b[0m\u001b[1;32m    825\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    932\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_updates\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    911\u001b[0m                             metric_result = weighted_metric_fn(y_true, y_pred,\n\u001b[1;32m    912\u001b[0m                                                                \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m                                                                mask=masks[i])\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                         \u001b[0;31m# Append to self.metrics_names, self.metric_tensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \"\"\"\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/metrics.py\u001b[0m in \u001b[0;36mcategorical_accuracy\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcategorical_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     return K.cast(K.equal(K.argmax(y_true, axis=-1),\n\u001b[0m\u001b[1;32m     32\u001b[0m                           K.argmax(y_pred, axis=-1)),\n\u001b[1;32m     33\u001b[0m                   K.floatx())\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \"\"\"\n\u001b[0;32m-> 1410\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(input, axis, name, dimension)\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot specify both 'axis' and 'dimension'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36marg_max\u001b[0;34m(input, dimension, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m   \"\"\"\n\u001b[1;32m    167\u001b[0m   result = _op_def_lib.apply_op(\"ArgMax\", input=input, dimension=dimension,\n\u001b[0;32m--> 168\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m    169\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    757\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    758\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2240\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2242\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2243\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1615\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1617\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1618\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension (-1) must be in the range [0, 2), where 2 is the number of dimensions in the input. for 'metrics/acc/ArgMax' (op: 'ArgMax') with input shapes: [?,?], []."
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "# MNIST model in Keras using sequential model building\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# compile the network with categorical crossentropy objective function and Adam optimizer. \n",
    "# other optimizers include Adam, Adadelta, etc \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n",
      "5\n",
      "(60000, 10)\n",
      "(10000, 10)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 128\n",
    "val_batch_size = 128\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)\n",
    "print(y_train[0])\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation generators\n",
    "train_generator =  custom_image_generator(\n",
    "    ImageDataGenerator(rescale=1./255),\n",
    "    x_train, y_train,\n",
    "    seed=1,  # Use a specific random seed\n",
    "    batch_size=train_batch_size,  # Use batch size of 128\n",
    "    )\n",
    "\n",
    "validation_generator =  custom_image_generator(\n",
    "    ImageDataGenerator(rescale=1./255),\n",
    "    x_test, y_test,\n",
    "    seed=1,  # Use a specific random seed\n",
    "    batch_size=val_batch_size,  #Use batch size of 128\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "468/468 [==============================] - 10s 22ms/step - loss: 0.2375 - acc: 0.9281 - val_loss: 0.0520 - val_acc: 0.9832\n",
      "Epoch 2/12\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.0856 - acc: 0.9745 - val_loss: 0.0399 - val_acc: 0.9856\n",
      "Epoch 3/12\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0617 - acc: 0.9810 - val_loss: 0.0325 - val_acc: 0.9889\n",
      "Epoch 4/12\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0506 - acc: 0.9845 - val_loss: 0.0389 - val_acc: 0.9874\n",
      "Epoch 5/12\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0437 - acc: 0.9866 - val_loss: 0.0324 - val_acc: 0.9884\n",
      "Epoch 6/12\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0383 - acc: 0.9882 - val_loss: 0.0305 - val_acc: 0.9900\n",
      "Epoch 7/12\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0336 - acc: 0.9889 - val_loss: 0.0328 - val_acc: 0.9901\n",
      "Epoch 8/12\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.0298 - acc: 0.9904 - val_loss: 0.0259 - val_acc: 0.9911\n",
      "Epoch 9/12\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0255 - acc: 0.9918 - val_loss: 0.0276 - val_acc: 0.9926\n",
      "Epoch 10/12\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0240 - acc: 0.9919 - val_loss: 0.0314 - val_acc: 0.9909\n",
      "Epoch 11/12\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.0214 - acc: 0.9928 - val_loss: 0.0298 - val_acc: 0.9917\n",
      "Epoch 12/12\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0205 - acc: 0.9935 - val_loss: 0.0282 - val_acc: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6ab14fb2e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 12\n",
    "\n",
    "# train the network for the number of epochs defined\n",
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=x_train.shape[0] // train_batch_size,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=x_test.shape[0] // val_batch_size,\n",
    "    epochs=epochs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained model\n",
    "model = load_model('models/mnist_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_height 225\n",
      "img_width 225\n",
      "(1, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load image\n",
    "img = Image.open('images/mnist_img_1.jpeg')\n",
    "imshow(img)\n",
    "print ('img_height', img.size[0])\n",
    "print ('img_width', img.size[1])\n",
    "# convert to grayscale and reshape the array to the network input size\n",
    "resized_img = img.resize((img_cols, img_rows))\n",
    "resized_img = resized_img.convert('L')\n",
    "resized_img = np.asarray(resized_img, dtype=np.float32)\n",
    "resized_img/=255\n",
    "resized_img = np.reshape(resized_img, (1, img_rows, img_cols, 1))\n",
    "print(resized_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax values: [[1.6903081e-04 1.2680322e-07 1.3373308e-03 3.6712136e-04 1.0917443e-05\n",
      "  1.8726547e-05 5.5147405e-07 5.5208504e-03 3.6758539e-04 9.9220771e-01]]\n",
      "This number is 9\n"
     ]
    }
   ],
   "source": [
    "# predict number based on the network output\n",
    "out = model.predict(resized_img)\n",
    "print (\"Softmax values:\", out)\n",
    "print(\"This number is\", out.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
